# -*- coding: utf-8 -*-
"""
æ–‡æ¡£è½¬æ¢è„šæœ¬: Docx -> Markdown (å¸¦ LLM å¢å¼º)
"""
import os
import re
import json
from pathlib import Path
from typing import List, Tuple
from docx import Document
from openai import OpenAI

# =============================================================================
# é…ç½®
# =============================================================================
# è„šæœ¬å·²ç§»åŠ¨åˆ° data/kb ç›®å½•ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„è·å–é¡¹ç›®æ ¹ç›®å½•
CURRENT_DIR = Path(__file__).parent.absolute()
PROJECT_DIR = CURRENT_DIR.parent.parent
INPUT_DIR = CURRENT_DIR
OUTPUT_DIR = CURRENT_DIR / "kb_md"

MODEL_NAME = "qwen-plus"
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
API_KEY = "sk-af0bd19b890d465ea71ca754cf2a6658"

if not API_KEY:
    raise RuntimeError("æœªé…ç½® DASHSCOPE_API_KEY")

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

# Markdown éª¨æ¶ (ä¿æŒåŸæ ·ä»¥ç¡®ä¿è¾“å‡ºç»“æ„)
MD_SKELETON = """# ğŸ›°ï¸ ã€ç³»ç»Ÿæ ‡é¢˜ã€‘ - çŸ¥è¯†åº“

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ã€é¢†åŸŸã€‘åœ¨è½¨æ•…éšœåˆ†æä¸“å®¶æ™ºèƒ½ä½“ã€‚ä½ çš„æ ¸å¿ƒèŒè´£æ˜¯åˆ©ç”¨æä¾›çš„å·¥å…·æ£€æµ‹ã€æ•…éšœå¯¹è±¡/å­ç³»ç»Ÿã€‘æ•…éšœï¼Œåˆ†ææ•…éšœæˆå› ï¼Œå¹¶è¯„ä¼°å…¶å¯¹ã€å®‰å…¨å½±å“å¯¹è±¡ã€‘çš„å®‰å…¨å½±å“ã€‚

## ğŸ› ï¸ å·¥å…·ä½¿ç”¨ä¸æ“ä½œæµç¨‹ (SOP)

å½“ç”¨æˆ·è¦æ±‚â€œåˆ†æã€æ•…éšœå¯¹è±¡/å­ç³»ç»Ÿã€‘æ•…éšœâ€æˆ–â€œè¯„ä¼°å«æ˜ŸçŠ¶æ€â€æ—¶ï¼Œè¯·**ä¸¥æ ¼**æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ‰§è¡Œï¼š

### ç¬¬ä¸€æ­¥ï¼šä¾¦å¯Ÿæ•…éšœ
è°ƒç”¨å·¥å…· `ã€å·¥å…·1åç§°ã€‘`ã€‚
*   **ç›®çš„**ï¼šè·å–ç²¾ç¡®çš„æ•…éšœå‘ç”Ÿæ—¶é—´æ®µã€‚
*   **è¾“å…¥**ï¼šå«æ˜Ÿåç§°ï¼ˆå¦‚ "æ±Ÿæ·®"ï¼‰ã€‚
*   **å†³ç­–**ï¼š
    *   å¦‚æœè¿”å› `status: "normal"`ï¼Œåˆ™å›å¤ç”¨æˆ·ä¸€åˆ‡æ­£å¸¸ï¼Œä»»åŠ¡ç»“æŸã€‚
    *   å¦‚æœè¿”å› `status: "fault_found"`ï¼Œæå–è¿”å›çš„ `fault_segments` åˆ—è¡¨ä¸­çš„ `start` å’Œ `end` æ—¶é—´ï¼Œè¿›å…¥ç¬¬äºŒæ­¥ã€‚

### ç¬¬äºŒæ­¥ï¼šå…³è”è°ƒæŸ¥ (å…³é”®)
è°ƒç”¨å·¥å…· `ã€å·¥å…·2åç§°ã€‘`ã€‚
*   **ç›®çš„**ï¼šè·å–æ•…éšœæœŸé—´çš„ç¯å¢ƒæ•°æ®å’Œã€å…³é”®ä¸šåŠ¡æ•°æ®ã€‘ã€‚
*   **è¾“å…¥çº¦æŸ (ä¸¥ç¦ä¿®æ”¹)**ï¼š
    *   `satellite_name`: ä¿æŒä¸€è‡´ã€‚
    *   `start_time_str` / `end_time_str`: **å¿…é¡»ä½¿ç”¨ç¬¬ä¸€æ­¥è¿”å›çš„ç²¾ç¡®æ•…éšœæ—¶é—´**ï¼ˆä¸è¦è‡ªè¡Œå¤–æ‰©ï¼Œå·¥å…·å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†ç»˜å›¾ä¸Šä¸‹æ–‡ï¼‰ã€‚
    *   `queries`: **å¿…é¡»ä¸”åªèƒ½** åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå‚æ•°å­—ç¬¦ä¸²ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼š
        `"ã€å‚æ•°1ã€‘,ã€å‚æ•°2ã€‘,ã€å‚æ•°3ã€‘"`
    *   **è­¦å‘Š**ï¼šä¸¥ç¦ç¼–é€ ç³»ç»Ÿä¸æ”¯æŒçš„å‚æ•°åã€‚

### ç¬¬ä¸‰æ­¥ï¼šé€»è¾‘æ¨ç†ä¸å®šæ€§
æ ¹æ®ç¬¬äºŒæ­¥è¿”å›çš„ JSON ç»Ÿè®¡æ•°æ®ï¼Œç»“åˆä¸‹æ–¹çš„ã€æ•…éšœåˆ¤æ®è¡¨ã€‘è¿›è¡Œæ¨ç†ã€‚

---

## âš–ï¸ æ•…éšœå®šæ€§åˆ¤æ® (Diagnostic Criteria)

è¯·æ ¹æ®å·¥å…·è¿”å›çš„ JSON æ•°æ®ä¸­çš„ç»Ÿè®¡æŒ‡æ ‡ï¼ˆ`start_val`, `mean_val`, `max_abs_val`ï¼‰è¿›è¡Œåˆ¤æ–­ã€‚

### ğŸŸ¢ ç±»å‹ Aï¼šå®‰å…¨æ•…éšœ (Safe/Low Risk)
**å®šä¹‰**ï¼šã€ç±»å‹Aå®šä¹‰ã€‘  
**åˆ¤å®šæ¡ä»¶**ï¼šå¿…é¡»**åŒæ—¶æ»¡è¶³**ä»¥ä¸‹æ‰€æœ‰æ¡ä»¶ï¼š

1.  **æ¡ä»¶1åç§°**ï¼š
    *   å‚æ•°ï¼š`ã€å‚æ•°å_å¯¹åº”å‚æ•°1æˆ–2æˆ–3ã€‘` -> `ã€ä½¿ç”¨çš„ç»Ÿè®¡é‡ï¼šstart_val/mean_val/max_abs_valã€‘`
    *   è§„åˆ™ï¼šã€é˜ˆå€¼è§„åˆ™1ã€‘
2.  **æ¡ä»¶2åç§°**ï¼š
    *   å‚æ•°ï¼š`ã€å‚æ•°å_å¯¹åº”å‚æ•°1æˆ–2æˆ–3ã€‘` -> `ã€ä½¿ç”¨çš„ç»Ÿè®¡é‡ï¼šstart_val/mean_val/max_abs_valã€‘`
    *   è§„åˆ™ï¼šã€é˜ˆå€¼è§„åˆ™2ã€‘
3.  **æ¡ä»¶3åç§°**ï¼š
    *   å‚æ•°ï¼š`ã€å‚æ•°å_å¯¹åº”å‚æ•°1æˆ–2æˆ–3ã€‘` -> `ã€ä½¿ç”¨çš„ç»Ÿè®¡é‡ï¼šstart_val/mean_val/max_abs_valã€‘`
    *   è§„åˆ™ï¼šã€é˜ˆå€¼è§„åˆ™3ã€‘

### ğŸ”´ ç±»å‹ Bï¼šå±é™©æ•…éšœ (High Risk)
**å®šä¹‰**ï¼šã€ç±»å‹Bå®šä¹‰ã€‘  
**åˆ¤å®šæ¡ä»¶**ï¼šæ»¡è¶³**ä»»æ„ä¸€æ¡**ä»¥ä¸‹æ¡ä»¶ï¼š

1.  **å±é™©æ¡ä»¶1åç§°**ï¼šã€å±é™©è§„åˆ™1ã€‘
2.  **å±é™©æ¡ä»¶2åç§°**ï¼šã€å±é™©è§„åˆ™2ã€‘
3.  **å±é™©æ¡ä»¶3åç§°**ï¼šã€å±é™©è§„åˆ™3ã€‘

---

## ğŸ“ å“åº”è¾“å‡ºæ¨¡æ¿ (Response Template)

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å‘ç”¨æˆ·æ±‡æŠ¥åˆ†æç»“æœï¼š

> **ğŸ“Š ã€æ•…éšœå¯¹è±¡/å­ç³»ç»Ÿã€‘æ•…éšœåˆ†ææŠ¥å‘Š - [å«æ˜Ÿåç§°]**
>
> **1. æ•…éšœæ¦‚å†µ**
> *   æ£€æµ‹åˆ° **[N]** æ¬¡ã€æ•…éšœäº‹ä»¶/è®¡æ•°ã€‘å¢åŠ ã€‚
> *   ä¸»è¦æ•…éšœæ—¶æ®µï¼š`YYYY-MM-DD HH:MM:SS` è‡³ `HH:MM:SS`
> *   ã€å…³é”®å¢é‡å­—æ®µåã€‘ï¼š**[æ•°å€¼]**
>
> **2. å…³è”æ•°æ®æ ¸æŸ¥**
> *   **ã€ç»´åº¦1åç§°ã€‘**ï¼šæ•…éšœèµ·å§‹ã€ç»´åº¦1ã€‘ä¸º **[Val1]**ï¼ˆã€è§£é‡Šï¼šæ­£å¸¸/å¼‚å¸¸ã€‘ï¼‰ã€‚
> *   **ã€ç»´åº¦2åç§°ã€‘**ï¼šæœŸé—´å¹³å‡ã€ç»´åº¦2ã€‘ä¸º **[Val2]**ã€‚
> *   **ã€ç»´åº¦3åç§°ã€‘**ï¼šæœŸé—´ã€ç»´åº¦3ã€‘æœ€å¤§ç»å¯¹å€¼ä¸º **[Val3]**ã€‚
>
> **3. ä¸“å®¶ç»“è®º**
> *   **å®šæ€§ç»“æœ**ï¼š**[å®‰å…¨æ•…éšœ / å±é™©æ•…éšœ]**
> *   **åˆ¤å®šä¾æ®**ï¼š[ç”¨åˆ¤æ®é€æ¡å¯¹åº”è§£é‡Šï¼›å¹¶åœ¨æœ«å°¾è¿½åŠ â€œæ¨æ–­é¡¹æ¸…å•ï¼š...â€ã€‘ã€æ­¤è¡Œå¿…é¡»åŒ…å«æ¨æ–­é¡¹æ¸…å•ã€‘
>
> ğŸ”— *è¯¦ç»†è¶‹åŠ¿å›¾è¡¨å·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹è‡ªåŠ¨å¼¹å‡ºçš„ HTML æŠ¥å‘Šã€‚*

---

### ğŸ’¡ System Tip
è®°ä½ï¼šä½ ä¸æ˜¯åœ¨çŒœæµ‹ï¼Œä½ æ˜¯åœ¨æ ¹æ®ä¸¥æ ¼çš„æ•°æ®å’Œè§„åˆ™è¿›è¡Œè¯Šæ–­ã€‚å¦‚æœä½ ä½¿ç”¨äº†æ¨æ–­è¡¥å…¨ï¼Œå¿…é¡»æ˜¾å¼æ ‡æ³¨å¹¶åˆ—å‡ºæ¨æ–­é¡¹æ¸…å•ã€‚
"""

MUST_HAVE_HEADERS = [
    "# ğŸ›°ï¸", "## ğŸ› ï¸ å·¥å…·ä½¿ç”¨ä¸æ“ä½œæµç¨‹ (SOP)",
    "### ç¬¬ä¸€æ­¥ï¼šä¾¦å¯Ÿæ•…éšœ", "### ç¬¬äºŒæ­¥ï¼šå…³è”è°ƒæŸ¥ (å…³é”®)", "### ç¬¬ä¸‰æ­¥ï¼šé€»è¾‘æ¨ç†ä¸å®šæ€§",
    "## âš–ï¸ æ•…éšœå®šæ€§åˆ¤æ® (Diagnostic Criteria)",
    "### ğŸŸ¢ ç±»å‹ Aï¼šå®‰å…¨æ•…éšœ (Safe/Low Risk)",
    "### ğŸ”´ ç±»å‹ Bï¼šå±é™©æ•…éšœ (High Risk)",
    "## ğŸ“ å“åº”è¾“å‡ºæ¨¡æ¿ (Response Template)",
    "### ğŸ’¡ System Tip",
]

# =============================================================================
# åŠŸèƒ½å‡½æ•°
# =============================================================================

def read_docx_text(docx_path: Path) -> str:
    """è¯»å– docx æ–‡æœ¬å†…å®¹"""
    doc = Document(str(docx_path))
    return "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])

def _clean_param_name(s: str) -> str:
    """æ¸…æ´—å‚æ•°å"""
    s = (s or "").strip().strip('"\'').replace("ï¼Œ", ",").replace(",", " ")
    s = re.sub(r"\s+", " ", s)
    return s or "å‚æ•°ï¼ˆæ¨æ–­ï¼‰"

def llm_pick_three_params(incident_text: str, doc_title: str) -> Tuple[List[str], str]:
    """ä½¿ç”¨ LLM æå– 3 ä¸ªå…³é”®å‚æ•°"""
    prompt = f"""
åªè¾“å‡º JSONã€‚ä¸ºâ€œè¶‹åŠ¿å…³è”è°ƒæŸ¥ queriesâ€é€‰æ‹© 3 ä¸ªå‚æ•°åï¼ˆé€—å·åˆ†éš”å­—æ®µï¼‰ï¼Œè¦æ±‚ï¼š
- ä¸å«é€—å·
- è¦†ç›–ï¼šæ•…éšœè§¦å‘/è¡¨ç°ã€å…³é”®å•æœºæˆ–åŸºå‡†çŠ¶æ€ã€å¯¹å§¿æ€/å®‰å…¨å½±å“
- åŸæ–‡ç¼ºå¤±å¯æŒ‰å¸¸è¯†æ¨æ–­ï¼Œå¹¶åœ¨æœ«å°¾åŠ â€œï¼ˆæ¨æ–­ï¼‰â€
- æ ¼å¼ï¼š{{"params":["p1","p2","p3"],"rationale":"ä¸€å¥è¯è§£é‡Š"}}

ã€æ–‡æ¡£æ ‡é¢˜ã€‘{doc_title}
ã€æ•…éšœåŸæ–‡ã€‘{incident_text}
""".strip()

    try:
        resp = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "system", "content": "åªè¾“å‡ºä¸¥æ ¼ JSONã€‚"}, {"role": "user", "content": prompt}],
            temperature=0.1,
        )
        text = (resp.choices[0].message.content or "").strip()
        if m := re.search(r"\{.*\}", text, flags=re.S):
            text = m.group(0).strip()

        obj = json.loads(text)
        params = [_clean_param_name(str(x)) for x in obj.get("params", [])]
        rationale = obj.get("rationale", "æ— ")
        
        # è¡¥é½å‚æ•°
        while len(params) < 3: params.append("å‚æ•°ï¼ˆæ¨æ–­ï¼‰")
        return params[:3], rationale
    except Exception as e:
        return ["å§¿æ€è¯¯å·®ï¼ˆæ¨æ–­ï¼‰", "åŸºå‡†é€‰æ‹©ï¼ˆæ¨æ–­ï¼‰", "å•æœºçŠ¶æ€ï¼ˆæ¨æ–­ï¼‰"], f"è§£æå¤±è´¥: {e}"

def llm_generate_markdown_full(incident_text: str, doc_title: str, params: List[str], param_rationale: str) -> str:
    """ç”Ÿæˆå®Œæ•´ Markdown"""
    q_str = f"{params[0]},{params[1]},{params[2]}"
    prompt = f"""
è¾“å‡ºä¸€ä»½ Markdownï¼Œç»“æ„å¿…é¡»ä¸â€œéª¨æ¶â€å®Œå…¨ä¸€è‡´ã€‚
ä»»åŠ¡ï¼šç†è§£æ•…éšœåŸæ–‡ï¼Œè¡¥é½éª¨æ¶ä¸­çš„æ‰€æœ‰å ä½ç¬¦ã€‚

ã€è§„åˆ™ã€‘
1) ä¸å…è®¸å‡ºç° â€œã€â€ æˆ– â€œã€‘â€ã€‚
2) ç¼ºå¤±ä¿¡æ¯æŒ‰å¸¸è¯†æ¨æ–­ï¼Œå¹¶æ ‡æ³¨â€œï¼ˆæ¨æ–­ï¼‰â€ã€‚
3) queries è¡Œå¿…é¡»ä¸ºï¼š"{q_str}"ã€‚
4) åˆ¤æ®å‚æ•°å¿…é¡»å¼•ç”¨ params ä¸­çš„åå­—ã€‚
5) â€œåˆ¤å®šä¾æ®â€æœ«å°¾å¿…é¡»è¿½åŠ ï¼šæ¨æ–­é¡¹æ¸…å•ï¼š...

ã€éª¨æ¶ã€‘
{MD_SKELETON}

ã€å‚æ•°ã€‘
- P1={params[0]}, P2={params[1]}, P3={params[2]}
- ç†ç”±={param_rationale}

ã€è¾“å…¥ã€‘
æ ‡é¢˜ï¼š{doc_title}
åŸæ–‡ï¼š{incident_text}
""".strip()

    resp = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯èˆªå¤©åœ¨è½¨æ•…éšœçŸ¥è¯†åº“æ–‡æ¡£å·¥ç¨‹å¸ˆï¼šä¸¥æ ¼æŒ‰éª¨æ¶è¾“å‡ºï¼ŒåŒºåˆ†äº‹å®ä¸æ¨æ–­ã€‚"},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )
    md = (resp.choices[0].message.content or "").strip()

    # æ ¡éªŒä¸ä¿®å¤
    for h in MUST_HAVE_HEADERS:
        if h not in md: raise ValueError(f"ç¼ºå°‘ç»“æ„ï¼š{h}")

    if "ã€" in md:
        md = re.sub(r"ã€[^ã€‘]+ã€‘", "å†…å®¹ï¼ˆæ¨æ–­ï¼‰", md)
        if "ã€" in md: raise ValueError("å­˜åœ¨æœªæ›¿æ¢å ä½ç¬¦")

    if f"\"{q_str}\"" not in md:
        raise ValueError(f"queries ä¸åŒ¹é…ï¼ŒæœŸæœ›åŒ…å« \"{q_str}\"")

    # è‡ªåŠ¨è¡¥å…¨æ¨æ–­æ¸…å•
    if "æ¨æ–­é¡¹æ¸…å•ï¼š" not in md:
        md = md.replace("æ¨æ–­é¡¹æ¸…å•:", "æ¨æ–­é¡¹æ¸…å•ï¼š")
        if "æ¨æ–­é¡¹æ¸…å•ï¼š" not in md:
            if m := re.search(r"(\*\*åˆ¤å®šä¾æ®\*\*ï¼š.*)", md):
                md = re.sub(r"(\*\*åˆ¤å®šä¾æ®\*\*ï¼š.*)", r"\1 æ¨æ–­é¡¹æ¸…å•ï¼šæ— ", md)
            else:
                md += "\n\næ¨æ–­é¡¹æ¸…å•ï¼šæ— "

    return md

def main():
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"è¾“å…¥ç›®å½•: {INPUT_DIR}")
    
    if not INPUT_DIR.exists():
        raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    docx_files = sorted(INPUT_DIR.glob("*.docx"))
    
    if not docx_files:
        raise FileNotFoundError("æœªæ‰¾åˆ° .docx æ–‡ä»¶")

    for docx_path in docx_files:
        print(f"[+] å¤„ç†: {docx_path.name}")
        text = read_docx_text(docx_path)
        params, rationale = llm_pick_three_params(text, docx_path.stem)
        print(f"    å‚æ•°: {params} | ç†ç”±: {rationale}")

        md = llm_generate_markdown_full(text, docx_path.stem, params, rationale)
        
        out_path = OUTPUT_DIR / (docx_path.stem + ".md")
        out_path.write_text(md, encoding="utf-8")
        print(f"    -> è¾“å‡º: {out_path.name}")

    print(f"\nå®Œæˆ: å…± {len(docx_files)} ä¸ªæ–‡ä»¶")

if __name__ == "__main__":
    main()
