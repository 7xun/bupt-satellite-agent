# -*- coding: utf-8 -*-
"""
æŒ‰å‘¨åˆ‡åˆ† CSV æ–‡ä»¶è„šæœ¬
"""
import pandas as pd
import os

# =============================================================================
# é…ç½®
# =============================================================================
# è¾“å…¥æ–‡ä»¶è·¯å¾„ (å‡è®¾åœ¨é¡¹ç›®æ ¹ç›®å½•)
INPUT_FILE = os.path.join(os.path.dirname(os.path.dirname(__file__)), '0x0821.csv')

# è¾“å‡ºç›®å½• (åœ¨ oss æ–‡ä»¶å¤¹ä¸‹)
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "oss", "processed_data", "0x0821")

def slice_csv_by_week():
    # 1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        # å°è¯•æŸ¥æ‰¾å¸¦ä¸‹åˆ’çº¿çš„æ–‡ä»¶åï¼Œä»¥é˜²ä¸‡ä¸€
        alt_file = INPUT_FILE.replace('.csv', '_.csv')
        if os.path.exists(alt_file):
            print(f"âš ï¸ æ‰¾åˆ°æ›¿ä»£æ–‡ä»¶: {alt_file}ï¼Œå°†ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚")
            input_path = alt_file
        else:
            return
    else:
        input_path = INPUT_FILE

    print(f"æ­£åœ¨è¯»å–æ–‡ä»¶: {input_path} ...")
    
    # 4. åˆ›å»ºè¾“å‡ºç›®å½• (æå‰åˆ›å»º)
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"å·²åˆ›å»ºè¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    # ç”¨äºè®°å½•æœ¬æ¬¡è¿è¡Œå·²åˆ›å»ºçš„æ–‡ä»¶ï¼Œé¿å…è¿½åŠ åˆ°æ—§æ–‡ä»¶
    initialized_files = set()
    total_rows = 0
    chunk_size = 100000  # æ¯æ¬¡å¤„ç† 10 ä¸‡è¡Œ

    try:
        # 2. åˆ†å—è¯»å– CSV
        reader = pd.read_csv(input_path, chunksize=chunk_size)
        
        for i, df in enumerate(reader):
            if 'time' not in df.columns:
                print("âŒ é”™è¯¯: CSV æ–‡ä»¶ä¸­ç¼ºå°‘ 'time' åˆ—ã€‚")
                return

            print(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} ä¸ªåˆ†å— (è¡Œæ•°: {len(df)})...")
            total_rows += len(df)

            # 3. å¤„ç†æ—¶é—´åˆ—
            # å‡è®¾ time åˆ—æ˜¯çº³ç§’æ—¶é—´æˆ³ (int64)
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œpd.to_datetime ä¹Ÿèƒ½æ™ºèƒ½è¯†åˆ«
            df['temp_datetime'] = pd.to_datetime(df['time'], unit='ns')
            
            # æå– ISO å¹´ä»½å’Œå‘¨æ•°
            # æ³¨æ„ï¼šä½¿ç”¨ isocalendar å¯ä»¥é¿å…è·¨å¹´å‘¨çš„é—®é¢˜
            iso_cal = df['temp_datetime'].dt.isocalendar()
            df['year'] = iso_cal.year
            df['week'] = iso_cal.week
            
            # 5. åˆ†ç»„å¹¶ä¿å­˜ (è¿½åŠ æ¨¡å¼)
            grouped = df.groupby(['year', 'week'])
            
            for (year, week), group in grouped:
                # æ„é€ æ–‡ä»¶å: YYYY_WW.csv (ä¾‹å¦‚ 2023_08.csv)
                filename = f"{year}_{week:02d}.csv"
                filepath = os.path.join(OUTPUT_DIR, filename)
                
                # åˆ é™¤è¾…åŠ©åˆ—ï¼Œä¿æŒåŸæ ·è¾“å‡º
                output_df = group.drop(columns=['temp_datetime', 'year', 'week'])
                
                # ç¡®å®šå†™å…¥æ¨¡å¼å’Œæ˜¯å¦å†™å…¥è¡¨å¤´
                if filepath not in initialized_files:
                    mode = 'w' # ç¬¬ä¸€æ¬¡å†™å…¥è¯¥æ–‡ä»¶ï¼Œè¦†ç›–æ—§æ–‡ä»¶
                    header = True
                    initialized_files.add(filepath)
                    print(f"   -> åˆ›å»º/è¦†ç›–æ–‡ä»¶: {filename}")
                else:
                    mode = 'a' # åç»­å†™å…¥ï¼Œè¿½åŠ 
                    header = False
                
                output_df.to_csv(filepath, index=False, encoding='utf-8-sig', mode=mode, header=header)

        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç† {total_rows} è¡Œæ•°æ®ã€‚")
        print(f"æ–‡ä»¶ä¿å­˜åœ¨: {OUTPUT_DIR}")

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == '__main__':
    slice_csv_by_week()
